{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "i5Jm3UN_Hfsu"
   },
   "source": [
    "## **Homework 4**\n",
    "**Instructions**\n",
    "* This homework focuses on understanding and applying CoCoOp for CLIP prompt tuning. It consists of **four questions** designed to assess both theoretical understanding and practical application.\n",
    "\n",
    "* Please organize your answers and results for the questions below and submit this jupyter notebook as **a .pdf file**.\n",
    "\n",
    "* **Deadline: 11/26 (Sat) 23:59**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "QeRABv42Ku4E"
   },
   "source": [
    "### **Preparation**\n",
    "\n",
    "* Run the code below before proceeding with the homework (Q1, Q2).\n",
    "* If an error occurs, click ‘Run Session Again’ and then restart the runtime from the beginning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "jNOsgBEzKucv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zelbo\\Documents\\__SHARING FOLDER\\University\\Year K\\Deep Learning\\Homework\\KUDeepLearning\\DL_HW4\\ProMetaR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'ProMetaR' already exists and is not an empty directory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zelbo\\Documents\\__SHARING FOLDER\\University\\Year K\\Deep Learning\\Homework\\KUDeepLearning\\DL_HW4\\ProMetaR\\Dassl.pytorch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'Dassl.pytorch' already exists and is not an empty directory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: flake8==3.7.9 in c:\\users\\zelbo\\appdata\\roaming\\python\\python311\\site-packages (from -r requirements.txt (line 1)) (3.7.9)\n",
      "Requirement already satisfied: yapf==0.29.0 in c:\\users\\zelbo\\anaconda3\\envs\\dassl\\lib\\site-packages (from -r requirements.txt (line 2)) (0.29.0)\n",
      "Requirement already satisfied: isort==4.3.21 in c:\\users\\zelbo\\appdata\\roaming\\python\\python311\\site-packages (from -r requirements.txt (line 3)) (4.3.21)\n",
      "Requirement already satisfied: yacs in c:\\users\\zelbo\\anaconda3\\envs\\dassl\\lib\\site-packages (from -r requirements.txt (line 4)) (0.1.8)\n",
      "Requirement already satisfied: gdown in c:\\users\\zelbo\\appdata\\roaming\\python\\python311\\site-packages (from -r requirements.txt (line 5)) (5.2.0)\n",
      "Requirement already satisfied: tb-nightly in c:\\users\\zelbo\\appdata\\roaming\\python\\python311\\site-packages (from -r requirements.txt (line 6)) (2.19.0a20241120)\n",
      "Requirement already satisfied: future in c:\\users\\zelbo\\appdata\\roaming\\python\\python311\\site-packages (from -r requirements.txt (line 7)) (1.0.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\zelbo\\appdata\\roaming\\python\\python311\\site-packages (from -r requirements.txt (line 8)) (1.10.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\zelbo\\anaconda3\\envs\\dassl\\lib\\site-packages (from -r requirements.txt (line 9)) (1.5.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\zelbo\\anaconda3\\envs\\dassl\\lib\\site-packages (from -r requirements.txt (line 10)) (4.67.0)\n",
      "Requirement already satisfied: ftfy in c:\\users\\zelbo\\anaconda3\\envs\\dassl\\lib\\site-packages (from -r requirements.txt (line 11)) (6.3.1)\n",
      "Requirement already satisfied: regex in c:\\users\\zelbo\\anaconda3\\envs\\dassl\\lib\\site-packages (from -r requirements.txt (line 12)) (2024.11.6)\n",
      "Requirement already satisfied: wilds==1.2.2 in c:\\users\\zelbo\\appdata\\roaming\\python\\python311\\site-packages (from -r requirements.txt (line 13)) (1.2.2)\n",
      "Requirement already satisfied: tabulate in c:\\users\\zelbo\\anaconda3\\envs\\dassl\\lib\\site-packages (from -r requirements.txt (line 14)) (0.9.0)\n",
      "Requirement already satisfied: entrypoints<0.4.0,>=0.3.0 in c:\\users\\zelbo\\appdata\\roaming\\python\\python311\\site-packages (from flake8==3.7.9->-r requirements.txt (line 1)) (0.3)\n",
      "Requirement already satisfied: pyflakes<2.2.0,>=2.1.0 in c:\\users\\zelbo\\anaconda3\\envs\\dassl\\lib\\site-packages (from flake8==3.7.9->-r requirements.txt (line 1)) (2.1.1)\n",
      "Requirement already satisfied: pycodestyle<2.6.0,>=2.5.0 in c:\\users\\zelbo\\anaconda3\\envs\\dassl\\lib\\site-packages (from flake8==3.7.9->-r requirements.txt (line 1)) (2.5.0)\n",
      "Requirement already satisfied: mccabe<0.7.0,>=0.6.0 in c:\\users\\zelbo\\anaconda3\\envs\\dassl\\lib\\site-packages (from flake8==3.7.9->-r requirements.txt (line 1)) (0.6.1)\n",
      "Requirement already satisfied: numpy>=1.19.1 in c:\\users\\zelbo\\appdata\\roaming\\python\\python311\\site-packages (from wilds==1.2.2->-r requirements.txt (line 13)) (1.23.5)\n",
      "Requirement already satisfied: ogb>=1.2.6 in c:\\users\\zelbo\\appdata\\roaming\\python\\python311\\site-packages (from wilds==1.2.2->-r requirements.txt (line 13)) (1.3.6)\n",
      "Requirement already satisfied: outdated>=0.2.0 in c:\\users\\zelbo\\appdata\\roaming\\python\\python311\\site-packages (from wilds==1.2.2->-r requirements.txt (line 13)) (0.2.2)\n",
      "Requirement already satisfied: pandas>=1.1.0 in c:\\users\\zelbo\\appdata\\roaming\\python\\python311\\site-packages (from wilds==1.2.2->-r requirements.txt (line 13)) (2.0.3)\n",
      "Requirement already satisfied: pillow>=7.2.0 in c:\\users\\zelbo\\anaconda3\\envs\\dassl\\lib\\site-packages (from wilds==1.2.2->-r requirements.txt (line 13)) (11.0.0)\n",
      "Requirement already satisfied: pytz>=2020.4 in c:\\users\\zelbo\\anaconda3\\envs\\dassl\\lib\\site-packages (from wilds==1.2.2->-r requirements.txt (line 13)) (2024.2)\n",
      "Requirement already satisfied: torch>=1.7.0 in c:\\users\\zelbo\\appdata\\roaming\\python\\python311\\site-packages (from wilds==1.2.2->-r requirements.txt (line 13)) (2.4.1+cu118)\n",
      "Requirement already satisfied: torchvision>=0.8.2 in c:\\users\\zelbo\\appdata\\roaming\\python\\python311\\site-packages (from wilds==1.2.2->-r requirements.txt (line 13)) (0.19.1+cu118)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\zelbo\\appdata\\roaming\\python\\python311\\site-packages (from yacs->-r requirements.txt (line 4)) (6.0.2)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\zelbo\\appdata\\roaming\\python\\python311\\site-packages (from gdown->-r requirements.txt (line 5)) (4.12.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\zelbo\\appdata\\roaming\\python\\python311\\site-packages (from gdown->-r requirements.txt (line 5)) (3.13.1)\n",
      "Requirement already satisfied: requests[socks] in c:\\users\\zelbo\\appdata\\roaming\\python\\python311\\site-packages (from gdown->-r requirements.txt (line 5)) (2.31.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in c:\\users\\zelbo\\appdata\\roaming\\python\\python311\\site-packages (from tb-nightly->-r requirements.txt (line 6)) (2.1.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in c:\\users\\zelbo\\appdata\\roaming\\python\\python311\\site-packages (from tb-nightly->-r requirements.txt (line 6)) (1.68.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\zelbo\\appdata\\roaming\\python\\python311\\site-packages (from tb-nightly->-r requirements.txt (line 6)) (3.7)\n",
      "Requirement already satisfied: packaging in c:\\users\\zelbo\\appdata\\roaming\\python\\python311\\site-packages (from tb-nightly->-r requirements.txt (line 6)) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in c:\\users\\zelbo\\appdata\\roaming\\python\\python311\\site-packages (from tb-nightly->-r requirements.txt (line 6)) (5.28.3)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\zelbo\\anaconda3\\envs\\dassl\\lib\\site-packages (from tb-nightly->-r requirements.txt (line 6)) (75.1.0)\n",
      "Requirement already satisfied: six>1.9 in c:\\users\\zelbo\\appdata\\roaming\\python\\python311\\site-packages (from tb-nightly->-r requirements.txt (line 6)) (1.16.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\zelbo\\anaconda3\\envs\\dassl\\lib\\site-packages (from tb-nightly->-r requirements.txt (line 6)) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\zelbo\\anaconda3\\envs\\dassl\\lib\\site-packages (from tb-nightly->-r requirements.txt (line 6)) (3.1.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\zelbo\\anaconda3\\envs\\dassl\\lib\\site-packages (from scikit-learn->-r requirements.txt (line 9)) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\zelbo\\anaconda3\\envs\\dassl\\lib\\site-packages (from scikit-learn->-r requirements.txt (line 9)) (3.5.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\zelbo\\appdata\\roaming\\python\\python311\\site-packages (from tqdm->-r requirements.txt (line 10)) (0.4.6)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\zelbo\\appdata\\roaming\\python\\python311\\site-packages (from ftfy->-r requirements.txt (line 11)) (0.2.5)\n",
      "Requirement already satisfied: urllib3>=1.24.0 in c:\\users\\zelbo\\anaconda3\\envs\\dassl\\lib\\site-packages (from ogb>=1.2.6->wilds==1.2.2->-r requirements.txt (line 13)) (2.2.3)\n",
      "Requirement already satisfied: littleutils in c:\\users\\zelbo\\appdata\\roaming\\python\\python311\\site-packages (from outdated>=0.2.0->wilds==1.2.2->-r requirements.txt (line 13)) (0.2.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\zelbo\\appdata\\roaming\\python\\python311\\site-packages (from pandas>=1.1.0->wilds==1.2.2->-r requirements.txt (line 13)) (2.8.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\zelbo\\appdata\\roaming\\python\\python311\\site-packages (from pandas>=1.1.0->wilds==1.2.2->-r requirements.txt (line 13)) (2024.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\zelbo\\anaconda3\\envs\\dassl\\lib\\site-packages (from torch>=1.7.0->wilds==1.2.2->-r requirements.txt (line 13)) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\zelbo\\anaconda3\\envs\\dassl\\lib\\site-packages (from torch>=1.7.0->wilds==1.2.2->-r requirements.txt (line 13)) (1.13.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\zelbo\\appdata\\roaming\\python\\python311\\site-packages (from torch>=1.7.0->wilds==1.2.2->-r requirements.txt (line 13)) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\zelbo\\appdata\\roaming\\python\\python311\\site-packages (from torch>=1.7.0->wilds==1.2.2->-r requirements.txt (line 13)) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\zelbo\\appdata\\roaming\\python\\python311\\site-packages (from torch>=1.7.0->wilds==1.2.2->-r requirements.txt (line 13)) (2024.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\zelbo\\appdata\\roaming\\python\\python311\\site-packages (from werkzeug>=1.0.1->tb-nightly->-r requirements.txt (line 6)) (2.1.5)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\zelbo\\appdata\\roaming\\python\\python311\\site-packages (from beautifulsoup4->gdown->-r requirements.txt (line 5)) (2.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\zelbo\\anaconda3\\envs\\dassl\\lib\\site-packages (from requests[socks]->gdown->-r requirements.txt (line 5)) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\zelbo\\anaconda3\\envs\\dassl\\lib\\site-packages (from requests[socks]->gdown->-r requirements.txt (line 5)) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\zelbo\\anaconda3\\envs\\dassl\\lib\\site-packages (from requests[socks]->gdown->-r requirements.txt (line 5)) (2024.8.30)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in c:\\users\\zelbo\\anaconda3\\envs\\dassl\\lib\\site-packages (from requests[socks]->gdown->-r requirements.txt (line 5)) (1.7.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\zelbo\\anaconda3\\envs\\dassl\\lib\\site-packages (from sympy->torch>=1.7.0->wilds==1.2.2->-r requirements.txt (line 13)) (1.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The system cannot find the file specified.\n",
      "c:\\Users\\zelbo\\Documents\\__SHARING FOLDER\\University\\Year K\\Deep Learning\\Homework\\KUDeepLearning\\DL_HW4\\ProMetaR\n",
      "Collecting ftfy==6.1.1 (from -r requirements.txt (line 1))\n",
      "  Using cached ftfy-6.1.1-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: regex in c:\\users\\zelbo\\anaconda3\\envs\\dassl\\lib\\site-packages (from -r requirements.txt (line 2)) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in c:\\users\\zelbo\\anaconda3\\envs\\dassl\\lib\\site-packages (from -r requirements.txt (line 3)) (4.67.0)\n",
      "Collecting learn2learn==0.2.0 (from -r requirements.txt (line 4))\n",
      "  Using cached learn2learn-0.2.0.tar.gz (7.0 MB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: wcwidth>=0.2.5 in c:\\users\\zelbo\\appdata\\roaming\\python\\python311\\site-packages (from ftfy==6.1.1->-r requirements.txt (line 1)) (0.2.5)\n",
      "Requirement already satisfied: numpy>=1.15.4 in c:\\users\\zelbo\\appdata\\roaming\\python\\python311\\site-packages (from learn2learn==0.2.0->-r requirements.txt (line 4)) (1.23.5)\n",
      "Collecting gym>=0.14.0 (from learn2learn==0.2.0->-r requirements.txt (line 4))\n",
      "  Using cached gym-0.26.2-py3-none-any.whl\n",
      "Requirement already satisfied: torch>=1.1.0 in c:\\users\\zelbo\\appdata\\roaming\\python\\python311\\site-packages (from learn2learn==0.2.0->-r requirements.txt (line 4)) (2.4.1+cu118)\n",
      "Requirement already satisfied: torchvision>=0.3.0 in c:\\users\\zelbo\\appdata\\roaming\\python\\python311\\site-packages (from learn2learn==0.2.0->-r requirements.txt (line 4)) (0.19.1+cu118)\n",
      "Requirement already satisfied: scipy in c:\\users\\zelbo\\appdata\\roaming\\python\\python311\\site-packages (from learn2learn==0.2.0->-r requirements.txt (line 4)) (1.10.1)\n",
      "Requirement already satisfied: requests in c:\\users\\zelbo\\appdata\\roaming\\python\\python311\\site-packages (from learn2learn==0.2.0->-r requirements.txt (line 4)) (2.31.0)\n",
      "Collecting gsutil (from learn2learn==0.2.0->-r requirements.txt (line 4))\n",
      "  Using cached gsutil-5.31-py3-none-any.whl\n",
      "Collecting qpth>=0.0.15 (from learn2learn==0.2.0->-r requirements.txt (line 4))\n",
      "  Using cached qpth-0.0.18-py3-none-any.whl\n",
      "Requirement already satisfied: colorama in c:\\users\\zelbo\\appdata\\roaming\\python\\python311\\site-packages (from tqdm->-r requirements.txt (line 3)) (0.4.6)\n",
      "Collecting cloudpickle>=1.2.0 (from gym>=0.14.0->learn2learn==0.2.0->-r requirements.txt (line 4))\n",
      "  Using cached cloudpickle-3.1.0-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting gym-notices>=0.0.4 (from gym>=0.14.0->learn2learn==0.2.0->-r requirements.txt (line 4))\n",
      "  Using cached gym_notices-0.0.8-py3-none-any.whl.metadata (1.0 kB)\n",
      "Collecting cvxpy>=1.1.0 (from qpth>=0.0.15->learn2learn==0.2.0->-r requirements.txt (line 4))\n",
      "  Using cached cvxpy-1.6.0-cp311-cp311-win_amd64.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\zelbo\\appdata\\roaming\\python\\python311\\site-packages (from torch>=1.1.0->learn2learn==0.2.0->-r requirements.txt (line 4)) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\zelbo\\anaconda3\\envs\\dassl\\lib\\site-packages (from torch>=1.1.0->learn2learn==0.2.0->-r requirements.txt (line 4)) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\zelbo\\anaconda3\\envs\\dassl\\lib\\site-packages (from torch>=1.1.0->learn2learn==0.2.0->-r requirements.txt (line 4)) (1.13.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\zelbo\\appdata\\roaming\\python\\python311\\site-packages (from torch>=1.1.0->learn2learn==0.2.0->-r requirements.txt (line 4)) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\zelbo\\appdata\\roaming\\python\\python311\\site-packages (from torch>=1.1.0->learn2learn==0.2.0->-r requirements.txt (line 4)) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\zelbo\\appdata\\roaming\\python\\python311\\site-packages (from torch>=1.1.0->learn2learn==0.2.0->-r requirements.txt (line 4)) (2024.2.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\zelbo\\anaconda3\\envs\\dassl\\lib\\site-packages (from torchvision>=0.3.0->learn2learn==0.2.0->-r requirements.txt (line 4)) (11.0.0)\n",
      "Collecting argcomplete>=1.9.4 (from gsutil->learn2learn==0.2.0->-r requirements.txt (line 4))\n",
      "  Using cached argcomplete-3.5.1-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting crcmod>=1.7 (from gsutil->learn2learn==0.2.0->-r requirements.txt (line 4))\n",
      "  Using cached crcmod-1.7-cp311-cp311-win_amd64.whl\n",
      "Collecting fasteners>=0.14.1 (from gsutil->learn2learn==0.2.0->-r requirements.txt (line 4))\n",
      "  Using cached fasteners-0.19-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting gcs-oauth2-boto-plugin>=3.2 (from gsutil->learn2learn==0.2.0->-r requirements.txt (line 4))\n",
      "  Using cached gcs_oauth2_boto_plugin-3.2-py3-none-any.whl\n",
      "Collecting google-apitools>=0.5.32 (from gsutil->learn2learn==0.2.0->-r requirements.txt (line 4))\n",
      "  Using cached google_apitools-0.5.32-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting httplib2==0.20.4 (from gsutil->learn2learn==0.2.0->-r requirements.txt (line 4))\n",
      "  Using cached httplib2-0.20.4-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting google-reauth>=0.1.0 (from gsutil->learn2learn==0.2.0->-r requirements.txt (line 4))\n",
      "  Using cached google_reauth-0.1.1-py2.py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting monotonic>=1.4 (from gsutil->learn2learn==0.2.0->-r requirements.txt (line 4))\n",
      "  Using cached monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting pyOpenSSL>=0.13 (from gsutil->learn2learn==0.2.0->-r requirements.txt (line 4))\n",
      "  Using cached pyOpenSSL-24.2.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting retry-decorator>=1.0.0 (from gsutil->learn2learn==0.2.0->-r requirements.txt (line 4))\n",
      "  Using cached retry_decorator-1.1.1-py2.py3-none-any.whl\n",
      "Requirement already satisfied: six>=1.16.0 in c:\\users\\zelbo\\appdata\\roaming\\python\\python311\\site-packages (from gsutil->learn2learn==0.2.0->-r requirements.txt (line 4)) (1.16.0)\n",
      "Collecting google-auth==2.17.0 (from google-auth[aiohttp]==2.17.0->gsutil->learn2learn==0.2.0->-r requirements.txt (line 4))\n",
      "  Using cached google_auth-2.17.0-py2.py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting google-auth-httplib2>=0.2.0 (from gsutil->learn2learn==0.2.0->-r requirements.txt (line 4))\n",
      "  Using cached google_auth_httplib2-0.2.0-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth==2.17.0->google-auth[aiohttp]==2.17.0->gsutil->learn2learn==0.2.0->-r requirements.txt (line 4))\n",
      "  Using cached cachetools-5.5.0-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth==2.17.0->google-auth[aiohttp]==2.17.0->gsutil->learn2learn==0.2.0->-r requirements.txt (line 4))\n",
      "  Using cached pyasn1_modules-0.4.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth==2.17.0->google-auth[aiohttp]==2.17.0->gsutil->learn2learn==0.2.0->-r requirements.txt (line 4))\n",
      "  Using cached rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting aiohttp<4.0.0dev,>=3.6.2 (from google-auth[aiohttp]==2.17.0->gsutil->learn2learn==0.2.0->-r requirements.txt (line 4))\n",
      "  Using cached aiohttp-3.11.6-cp311-cp311-win_amd64.whl.metadata (8.0 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in c:\\users\\zelbo\\appdata\\roaming\\python\\python311\\site-packages (from httplib2==0.20.4->gsutil->learn2learn==0.2.0->-r requirements.txt (line 4)) (3.0.9)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\zelbo\\anaconda3\\envs\\dassl\\lib\\site-packages (from requests->learn2learn==0.2.0->-r requirements.txt (line 4)) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\zelbo\\anaconda3\\envs\\dassl\\lib\\site-packages (from requests->learn2learn==0.2.0->-r requirements.txt (line 4)) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\zelbo\\anaconda3\\envs\\dassl\\lib\\site-packages (from requests->learn2learn==0.2.0->-r requirements.txt (line 4)) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\zelbo\\anaconda3\\envs\\dassl\\lib\\site-packages (from requests->learn2learn==0.2.0->-r requirements.txt (line 4)) (2024.8.30)\n",
      "Collecting osqp>=0.6.2 (from cvxpy>=1.1.0->qpth>=0.0.15->learn2learn==0.2.0->-r requirements.txt (line 4))\n",
      "  Using cached osqp-0.6.7.post3-cp311-cp311-win_amd64.whl.metadata (2.0 kB)\n",
      "Collecting clarabel>=0.5.0 (from cvxpy>=1.1.0->qpth>=0.0.15->learn2learn==0.2.0->-r requirements.txt (line 4))\n",
      "  Using cached clarabel-0.9.0-cp37-abi3-win_amd64.whl.metadata (4.8 kB)\n",
      "Collecting scs>=3.2.4.post1 (from cvxpy>=1.1.0->qpth>=0.0.15->learn2learn==0.2.0->-r requirements.txt (line 4))\n",
      "  Using cached scs-3.2.7-cp311-cp311-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth==2.17.0->google-auth[aiohttp]==2.17.0->gsutil->learn2learn==0.2.0->-r requirements.txt (line 4))\n",
      "  Using cached rsa-4.7.2-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting boto>=2.29.1 (from gcs-oauth2-boto-plugin>=3.2->gsutil->learn2learn==0.2.0->-r requirements.txt (line 4))\n",
      "  Using cached boto-2.49.0-py2.py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting oauth2client>=2.2.0 (from gcs-oauth2-boto-plugin>=3.2->gsutil->learn2learn==0.2.0->-r requirements.txt (line 4))\n",
      "  Using cached oauth2client-4.1.3-py2.py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting pyasn1>=0.1.3 (from rsa<5,>=3.1.4->google-auth==2.17.0->google-auth[aiohttp]==2.17.0->gsutil->learn2learn==0.2.0->-r requirements.txt (line 4))\n",
      "  Using cached pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting pyu2f (from google-reauth>=0.1.0->gsutil->learn2learn==0.2.0->-r requirements.txt (line 4))\n",
      "  Using cached pyu2f-0.1.5-py3-none-any.whl\n",
      "Collecting cryptography<44,>=41.0.5 (from pyOpenSSL>=0.13->gsutil->learn2learn==0.2.0->-r requirements.txt (line 4))\n",
      "  Using cached cryptography-43.0.3-cp39-abi3-win_amd64.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\zelbo\\appdata\\roaming\\python\\python311\\site-packages (from jinja2->torch>=1.1.0->learn2learn==0.2.0->-r requirements.txt (line 4)) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\zelbo\\anaconda3\\envs\\dassl\\lib\\site-packages (from sympy->torch>=1.1.0->learn2learn==0.2.0->-r requirements.txt (line 4)) (1.3.0)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp<4.0.0dev,>=3.6.2->google-auth[aiohttp]==2.17.0->gsutil->learn2learn==0.2.0->-r requirements.txt (line 4))\n",
      "  Using cached aiohappyeyeballs-2.4.3-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0dev,>=3.6.2->google-auth[aiohttp]==2.17.0->gsutil->learn2learn==0.2.0->-r requirements.txt (line 4))\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp<4.0.0dev,>=3.6.2->google-auth[aiohttp]==2.17.0->gsutil->learn2learn==0.2.0->-r requirements.txt (line 4))\n",
      "  Using cached attrs-24.2.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0dev,>=3.6.2->google-auth[aiohttp]==2.17.0->gsutil->learn2learn==0.2.0->-r requirements.txt (line 4))\n",
      "  Using cached frozenlist-1.5.0-cp311-cp311-win_amd64.whl.metadata (14 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0dev,>=3.6.2->google-auth[aiohttp]==2.17.0->gsutil->learn2learn==0.2.0->-r requirements.txt (line 4))\n",
      "  Using cached multidict-6.1.0-cp311-cp311-win_amd64.whl.metadata (5.1 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp<4.0.0dev,>=3.6.2->google-auth[aiohttp]==2.17.0->gsutil->learn2learn==0.2.0->-r requirements.txt (line 4))\n",
      "  Using cached propcache-0.2.0-cp311-cp311-win_amd64.whl.metadata (7.9 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp<4.0.0dev,>=3.6.2->google-auth[aiohttp]==2.17.0->gsutil->learn2learn==0.2.0->-r requirements.txt (line 4))\n",
      "  Using cached yarl-1.17.2-cp311-cp311-win_amd64.whl.metadata (68 kB)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\zelbo\\appdata\\roaming\\python\\python311\\site-packages (from cryptography<44,>=41.0.5->pyOpenSSL>=0.13->gsutil->learn2learn==0.2.0->-r requirements.txt (line 4)) (1.17.1)\n",
      "Collecting qdldl (from osqp>=0.6.2->cvxpy>=1.1.0->qpth>=0.0.15->learn2learn==0.2.0->-r requirements.txt (line 4))\n",
      "  Using cached qdldl-0.1.7.post4-cp311-cp311-win_amd64.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: pycparser in c:\\users\\zelbo\\appdata\\roaming\\python\\python311\\site-packages (from cffi>=1.12->cryptography<44,>=41.0.5->pyOpenSSL>=0.13->gsutil->learn2learn==0.2.0->-r requirements.txt (line 4)) (2.22)\n",
      "Using cached ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
      "Using cached google_auth-2.17.0-py2.py3-none-any.whl (178 kB)\n",
      "Using cached httplib2-0.20.4-py3-none-any.whl (96 kB)\n",
      "Using cached argcomplete-3.5.1-py3-none-any.whl (43 kB)\n",
      "Using cached cloudpickle-3.1.0-py3-none-any.whl (22 kB)\n",
      "Using cached cvxpy-1.6.0-cp311-cp311-win_amd64.whl (1.1 MB)\n",
      "Using cached fasteners-0.19-py3-none-any.whl (18 kB)\n",
      "Using cached rsa-4.7.2-py3-none-any.whl (34 kB)\n",
      "Using cached google_apitools-0.5.32-py3-none-any.whl (135 kB)\n",
      "Using cached google_auth_httplib2-0.2.0-py2.py3-none-any.whl (9.3 kB)\n",
      "Using cached google_reauth-0.1.1-py2.py3-none-any.whl (17 kB)\n",
      "Using cached gym_notices-0.0.8-py3-none-any.whl (3.0 kB)\n",
      "Using cached monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
      "Using cached pyOpenSSL-24.2.1-py3-none-any.whl (58 kB)\n",
      "Using cached aiohttp-3.11.6-cp311-cp311-win_amd64.whl (440 kB)\n",
      "Using cached boto-2.49.0-py2.py3-none-any.whl (1.4 MB)\n",
      "Using cached cachetools-5.5.0-py3-none-any.whl (9.5 kB)\n",
      "Using cached clarabel-0.9.0-cp37-abi3-win_amd64.whl (736 kB)\n",
      "Using cached cryptography-43.0.3-cp39-abi3-win_amd64.whl (3.1 MB)\n",
      "Using cached oauth2client-4.1.3-py2.py3-none-any.whl (98 kB)\n",
      "Using cached osqp-0.6.7.post3-cp311-cp311-win_amd64.whl (293 kB)\n",
      "Using cached pyasn1_modules-0.4.1-py3-none-any.whl (181 kB)\n",
      "Using cached scs-3.2.7-cp311-cp311-win_amd64.whl (8.4 MB)\n",
      "Using cached aiohappyeyeballs-2.4.3-py3-none-any.whl (14 kB)\n",
      "Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Using cached attrs-24.2.0-py3-none-any.whl (63 kB)\n",
      "Using cached frozenlist-1.5.0-cp311-cp311-win_amd64.whl (51 kB)\n",
      "Using cached multidict-6.1.0-cp311-cp311-win_amd64.whl (28 kB)\n",
      "Using cached propcache-0.2.0-cp311-cp311-win_amd64.whl (44 kB)\n",
      "Using cached pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Using cached yarl-1.17.2-cp311-cp311-win_amd64.whl (90 kB)\n",
      "Using cached qdldl-0.1.7.post4-cp311-cp311-win_amd64.whl (87 kB)\n",
      "Building wheels for collected packages: learn2learn\n",
      "  Building wheel for learn2learn (setup.py): started\n",
      "  Building wheel for learn2learn (setup.py): finished with status 'error'\n",
      "  Running setup.py clean for learn2learn\n",
      "Failed to build learn2learn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × python setup.py bdist_wheel did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [165 lines of output]\n",
      "      C:\\Users\\zelbo\\anaconda3\\envs\\dassl\\Lib\\site-packages\\setuptools\\__init__.py:94: _DeprecatedInstaller: setuptools.installer and fetch_build_eggs are deprecated.\n",
      "      !!\n",
      "      \n",
      "              ********************************************************************************\n",
      "              Requirements should be satisfied by a PEP 517 installer.\n",
      "              If you are using pip, you can try `pip install --use-pep517`.\n",
      "              ********************************************************************************\n",
      "      \n",
      "      !!\n",
      "        dist.fetch_build_eggs(dist.setup_requires)\n",
      "      running bdist_wheel\n",
      "      running build\n",
      "      running build_py\n",
      "      creating build\\lib.win-amd64-cpython-311\\learn2learn\n",
      "      copying learn2learn\\_version.py -> build\\lib.win-amd64-cpython-311\\learn2learn\n",
      "      copying learn2learn\\__init__.py -> build\\lib.win-amd64-cpython-311\\learn2learn\n",
      "      creating build\\lib.win-amd64-cpython-311\\tests\n",
      "      copying tests\\__init__.py -> build\\lib.win-amd64-cpython-311\\tests\n",
      "      creating build\\lib.win-amd64-cpython-311\\learn2learn\\algorithms\n",
      "      copying learn2learn\\algorithms\\base_learner.py -> build\\lib.win-amd64-cpython-311\\learn2learn\\algorithms\n",
      "      copying learn2learn\\algorithms\\gbml.py -> build\\lib.win-amd64-cpython-311\\learn2learn\\algorithms\n",
      "      copying learn2learn\\algorithms\\maml.py -> build\\lib.win-amd64-cpython-311\\learn2learn\\algorithms\n",
      "      copying learn2learn\\algorithms\\meta_sgd.py -> build\\lib.win-amd64-cpython-311\\learn2learn\\algorithms\n",
      "      copying learn2learn\\algorithms\\__init__.py -> build\\lib.win-amd64-cpython-311\\learn2learn\\algorithms\n",
      "      creating build\\lib.win-amd64-cpython-311\\learn2learn\\data\n",
      "      copying learn2learn\\data\\samplers.py -> build\\lib.win-amd64-cpython-311\\learn2learn\\data\n",
      "      copying learn2learn\\data\\utils.py -> build\\lib.win-amd64-cpython-311\\learn2learn\\data\n",
      "      copying learn2learn\\data\\__init__.py -> build\\lib.win-amd64-cpython-311\\learn2learn\\data\n",
      "      creating build\\lib.win-amd64-cpython-311\\learn2learn\\gym\n",
      "      copying learn2learn\\gym\\async_vec_env.py -> build\\lib.win-amd64-cpython-311\\learn2learn\\gym\n",
      "      copying learn2learn\\gym\\__init__.py -> build\\lib.win-amd64-cpython-311\\learn2learn\\gym\n",
      "      creating build\\lib.win-amd64-cpython-311\\learn2learn\\nn\n",
      "      copying learn2learn\\nn\\kroneckers.py -> build\\lib.win-amd64-cpython-311\\learn2learn\\nn\n",
      "      copying learn2learn\\nn\\metaoptnet.py -> build\\lib.win-amd64-cpython-311\\learn2learn\\nn\n",
      "      copying learn2learn\\nn\\misc.py -> build\\lib.win-amd64-cpython-311\\learn2learn\\nn\n",
      "      copying learn2learn\\nn\\protonet.py -> build\\lib.win-amd64-cpython-311\\learn2learn\\nn\n",
      "      copying learn2learn\\nn\\__init__.py -> build\\lib.win-amd64-cpython-311\\learn2learn\\nn\n",
      "      creating build\\lib.win-amd64-cpython-311\\learn2learn\\optim\n",
      "      copying learn2learn\\optim\\learnable_optimizer.py -> build\\lib.win-amd64-cpython-311\\learn2learn\\optim\n",
      "      copying learn2learn\\optim\\parameter_update.py -> build\\lib.win-amd64-cpython-311\\learn2learn\\optim\n",
      "      copying learn2learn\\optim\\__init__.py -> build\\lib.win-amd64-cpython-311\\learn2learn\\optim\n",
      "      creating build\\lib.win-amd64-cpython-311\\learn2learn\\text\n",
      "      copying learn2learn\\text\\__init__.py -> build\\lib.win-amd64-cpython-311\\learn2learn\\text\n",
      "      creating build\\lib.win-amd64-cpython-311\\learn2learn\\utils\n",
      "      copying learn2learn\\utils\\lightning.py -> build\\lib.win-amd64-cpython-311\\learn2learn\\utils\n",
      "      copying learn2learn\\utils\\__init__.py -> build\\lib.win-amd64-cpython-311\\learn2learn\\utils\n",
      "      creating build\\lib.win-amd64-cpython-311\\learn2learn\\vision\n",
      "      copying learn2learn\\vision\\transforms.py -> build\\lib.win-amd64-cpython-311\\learn2learn\\vision\n",
      "      copying learn2learn\\vision\\__init__.py -> build\\lib.win-amd64-cpython-311\\learn2learn\\vision\n",
      "      creating build\\lib.win-amd64-cpython-311\\learn2learn\\algorithms\\lightning\n",
      "      copying learn2learn\\algorithms\\lightning\\lightning_anil.py -> build\\lib.win-amd64-cpython-311\\learn2learn\\algorithms\\lightning\n",
      "      copying learn2learn\\algorithms\\lightning\\lightning_episodic_module.py -> build\\lib.win-amd64-cpython-311\\learn2learn\\algorithms\\lightning\n",
      "      copying learn2learn\\algorithms\\lightning\\lightning_maml.py -> build\\lib.win-amd64-cpython-311\\learn2learn\\algorithms\\lightning\n",
      "      copying learn2learn\\algorithms\\lightning\\lightning_metaoptnet.py -> build\\lib.win-amd64-cpython-311\\learn2learn\\algorithms\\lightning\n",
      "      copying learn2learn\\algorithms\\lightning\\lightning_protonet.py -> build\\lib.win-amd64-cpython-311\\learn2learn\\algorithms\\lightning\n",
      "      copying learn2learn\\algorithms\\lightning\\__init__.py -> build\\lib.win-amd64-cpython-311\\learn2learn\\algorithms\\lightning\n",
      "      creating build\\lib.win-amd64-cpython-311\\learn2learn\\gym\\envs\n",
      "      copying learn2learn\\gym\\envs\\meta_env.py -> build\\lib.win-amd64-cpython-311\\learn2learn\\gym\\envs\n",
      "      copying learn2learn\\gym\\envs\\subproc_vec_env.py -> build\\lib.win-amd64-cpython-311\\learn2learn\\gym\\envs\n",
      "      copying learn2learn\\gym\\envs\\__init__.py -> build\\lib.win-amd64-cpython-311\\learn2learn\\gym\\envs\n",
      "      creating build\\lib.win-amd64-cpython-311\\learn2learn\\gym\\envs\\metaworld\n",
      "      copying learn2learn\\gym\\envs\\metaworld\\metaworld.py -> build\\lib.win-amd64-cpython-311\\learn2learn\\gym\\envs\\metaworld\n",
      "      copying learn2learn\\gym\\envs\\metaworld\\__init__.py -> build\\lib.win-amd64-cpython-311\\learn2learn\\gym\\envs\\metaworld\n",
      "      creating build\\lib.win-amd64-cpython-311\\learn2learn\\gym\\envs\\mujoco\n",
      "      copying learn2learn\\gym\\envs\\mujoco\\ant_direction.py -> build\\lib.win-amd64-cpython-311\\learn2learn\\gym\\envs\\mujoco\n",
      "      copying learn2learn\\gym\\envs\\mujoco\\ant_forward_backward.py -> build\\lib.win-amd64-cpython-311\\learn2learn\\gym\\envs\\mujoco\n",
      "      copying learn2learn\\gym\\envs\\mujoco\\dummy_mujoco_env.py -> build\\lib.win-amd64-cpython-311\\learn2learn\\gym\\envs\\mujoco\n",
      "      copying learn2learn\\gym\\envs\\mujoco\\halfcheetah_forward_backward.py -> build\\lib.win-amd64-cpython-311\\learn2learn\\gym\\envs\\mujoco\n",
      "      copying learn2learn\\gym\\envs\\mujoco\\humanoid_direction.py -> build\\lib.win-amd64-cpython-311\\learn2learn\\gym\\envs\\mujoco\n",
      "      copying learn2learn\\gym\\envs\\mujoco\\humanoid_forward_backward.py -> build\\lib.win-amd64-cpython-311\\learn2learn\\gym\\envs\\mujoco\n",
      "      copying learn2learn\\gym\\envs\\mujoco\\__init__.py -> build\\lib.win-amd64-cpython-311\\learn2learn\\gym\\envs\\mujoco\n",
      "      creating build\\lib.win-amd64-cpython-311\\learn2learn\\gym\\envs\\particles\n",
      "      copying learn2learn\\gym\\envs\\particles\\particles_2d.py -> build\\lib.win-amd64-cpython-311\\learn2learn\\gym\\envs\\particles\n",
      "      copying learn2learn\\gym\\envs\\particles\\__init__.py -> build\\lib.win-amd64-cpython-311\\learn2learn\\gym\\envs\\particles\n",
      "      creating build\\lib.win-amd64-cpython-311\\learn2learn\\nn\\metalayers\n",
      "      copying learn2learn\\nn\\metalayers\\metamodule.py -> build\\lib.win-amd64-cpython-311\\learn2learn\\nn\\metalayers\n",
      "      copying learn2learn\\nn\\metalayers\\parameter_transform.py -> build\\lib.win-amd64-cpython-311\\learn2learn\\nn\\metalayers\n",
      "      copying learn2learn\\nn\\metalayers\\__init__.py -> build\\lib.win-amd64-cpython-311\\learn2learn\\nn\\metalayers\n",
      "      creating build\\lib.win-amd64-cpython-311\\learn2learn\\optim\\transforms\n",
      "      copying learn2learn\\optim\\transforms\\kronecker_transform.py -> build\\lib.win-amd64-cpython-311\\learn2learn\\optim\\transforms\n",
      "      copying learn2learn\\optim\\transforms\\metacurvature_transform.py -> build\\lib.win-amd64-cpython-311\\learn2learn\\optim\\transforms\n",
      "      copying learn2learn\\optim\\transforms\\module_transform.py -> build\\lib.win-amd64-cpython-311\\learn2learn\\optim\\transforms\n",
      "      copying learn2learn\\optim\\transforms\\transform_dictionary.py -> build\\lib.win-amd64-cpython-311\\learn2learn\\optim\\transforms\n",
      "      copying learn2learn\\optim\\transforms\\__init__.py -> build\\lib.win-amd64-cpython-311\\learn2learn\\optim\\transforms\n",
      "      creating build\\lib.win-amd64-cpython-311\\learn2learn\\optim\\update_rules\n",
      "      copying learn2learn\\optim\\update_rules\\differentiable_sgd.py -> build\\lib.win-amd64-cpython-311\\learn2learn\\optim\\update_rules\n",
      "      copying learn2learn\\optim\\update_rules\\__init__.py -> build\\lib.win-amd64-cpython-311\\learn2learn\\optim\\update_rules\n",
      "      creating build\\lib.win-amd64-cpython-311\\learn2learn\\text\\datasets\n",
      "      copying learn2learn\\text\\datasets\\news_classification.py -> build\\lib.win-amd64-cpython-311\\learn2learn\\text\\datasets\n",
      "      copying learn2learn\\text\\datasets\\__init__.py -> build\\lib.win-amd64-cpython-311\\learn2learn\\text\\datasets\n",
      "      creating build\\lib.win-amd64-cpython-311\\learn2learn\\vision\\benchmarks\n",
      "      copying learn2learn\\vision\\benchmarks\\cifarfs_benchmark.py -> build\\lib.win-amd64-cpython-311\\learn2learn\\vision\\benchmarks\n",
      "      copying learn2learn\\vision\\benchmarks\\fc100_benchmark.py -> build\\lib.win-amd64-cpython-311\\learn2learn\\vision\\benchmarks\n",
      "      copying learn2learn\\vision\\benchmarks\\mini_imagenet_benchmark.py -> build\\lib.win-amd64-cpython-311\\learn2learn\\vision\\benchmarks\n",
      "      copying learn2learn\\vision\\benchmarks\\omniglot_benchmark.py -> build\\lib.win-amd64-cpython-311\\learn2learn\\vision\\benchmarks\n",
      "      copying learn2learn\\vision\\benchmarks\\tiered_imagenet_benchmark.py -> build\\lib.win-amd64-cpython-311\\learn2learn\\vision\\benchmarks\n",
      "      copying learn2learn\\vision\\benchmarks\\__init__.py -> build\\lib.win-amd64-cpython-311\\learn2learn\\vision\\benchmarks\n",
      "      creating build\\lib.win-amd64-cpython-311\\learn2learn\\vision\\datasets\n",
      "      copying learn2learn\\vision\\datasets\\cifarfs.py -> build\\lib.win-amd64-cpython-311\\learn2learn\\vision\\datasets\n",
      "      copying learn2learn\\vision\\datasets\\cu_birds200.py -> build\\lib.win-amd64-cpython-311\\learn2learn\\vision\\datasets\n",
      "      copying learn2learn\\vision\\datasets\\describable_textures.py -> build\\lib.win-amd64-cpython-311\\learn2learn\\vision\\datasets\n",
      "      copying learn2learn\\vision\\datasets\\fc100.py -> build\\lib.win-amd64-cpython-311\\learn2learn\\vision\\datasets\n",
      "      copying learn2learn\\vision\\datasets\\fgvc_aircraft.py -> build\\lib.win-amd64-cpython-311\\learn2learn\\vision\\datasets\n",
      "      copying learn2learn\\vision\\datasets\\fgvc_fungi.py -> build\\lib.win-amd64-cpython-311\\learn2learn\\vision\\datasets\n",
      "      copying learn2learn\\vision\\datasets\\full_omniglot.py -> build\\lib.win-amd64-cpython-311\\learn2learn\\vision\\datasets\n",
      "      copying learn2learn\\vision\\datasets\\mini_imagenet.py -> build\\lib.win-amd64-cpython-311\\learn2learn\\vision\\datasets\n",
      "      copying learn2learn\\vision\\datasets\\quickdraw.py -> build\\lib.win-amd64-cpython-311\\learn2learn\\vision\\datasets\n",
      "      copying learn2learn\\vision\\datasets\\tiered_imagenet.py -> build\\lib.win-amd64-cpython-311\\learn2learn\\vision\\datasets\n",
      "      copying learn2learn\\vision\\datasets\\vgg_flowers.py -> build\\lib.win-amd64-cpython-311\\learn2learn\\vision\\datasets\n",
      "      copying learn2learn\\vision\\datasets\\__init__.py -> build\\lib.win-amd64-cpython-311\\learn2learn\\vision\\datasets\n",
      "      creating build\\lib.win-amd64-cpython-311\\learn2learn\\vision\\models\n",
      "      copying learn2learn\\vision\\models\\cnn4.py -> build\\lib.win-amd64-cpython-311\\learn2learn\\vision\\models\n",
      "      copying learn2learn\\vision\\models\\resnet12.py -> build\\lib.win-amd64-cpython-311\\learn2learn\\vision\\models\n",
      "      copying learn2learn\\vision\\models\\wrn28.py -> build\\lib.win-amd64-cpython-311\\learn2learn\\vision\\models\n",
      "      copying learn2learn\\vision\\models\\__init__.py -> build\\lib.win-amd64-cpython-311\\learn2learn\\vision\\models\n",
      "      creating build\\lib.win-amd64-cpython-311\\tests\\integration\n",
      "      copying tests\\integration\\maml_miniimagenet_test_notravis.py -> build\\lib.win-amd64-cpython-311\\tests\\integration\n",
      "      copying tests\\integration\\maml_omniglot_test.py -> build\\lib.win-amd64-cpython-311\\tests\\integration\n",
      "      copying tests\\integration\\protonets_miniimagenet_test_notravis.py -> build\\lib.win-amd64-cpython-311\\tests\\integration\n",
      "      copying tests\\integration\\__init__.py -> build\\lib.win-amd64-cpython-311\\tests\\integration\n",
      "      creating build\\lib.win-amd64-cpython-311\\tests\\unit\n",
      "      copying tests\\unit\\utils_test.py -> build\\lib.win-amd64-cpython-311\\tests\\unit\n",
      "      copying tests\\unit\\__init__.py -> build\\lib.win-amd64-cpython-311\\tests\\unit\n",
      "      creating build\\lib.win-amd64-cpython-311\\tests\\unit\\algorithms\n",
      "      copying tests\\unit\\algorithms\\gbml_test.py -> build\\lib.win-amd64-cpython-311\\tests\\unit\\algorithms\n",
      "      copying tests\\unit\\algorithms\\lightning_anil_test_notravis.py -> build\\lib.win-amd64-cpython-311\\tests\\unit\\algorithms\n",
      "      copying tests\\unit\\algorithms\\lightning_maml_test_notravis.py -> build\\lib.win-amd64-cpython-311\\tests\\unit\\algorithms\n",
      "      copying tests\\unit\\algorithms\\lightning_metaoptnet_test_notravis.py -> build\\lib.win-amd64-cpython-311\\tests\\unit\\algorithms\n",
      "      copying tests\\unit\\algorithms\\lightning_protonet_test_notravis.py -> build\\lib.win-amd64-cpython-311\\tests\\unit\\algorithms\n",
      "      copying tests\\unit\\algorithms\\maml_test.py -> build\\lib.win-amd64-cpython-311\\tests\\unit\\algorithms\n",
      "      copying tests\\unit\\algorithms\\metasgd_test.py -> build\\lib.win-amd64-cpython-311\\tests\\unit\\algorithms\n",
      "      copying tests\\unit\\algorithms\\__init__.py -> build\\lib.win-amd64-cpython-311\\tests\\unit\\algorithms\n",
      "      creating build\\lib.win-amd64-cpython-311\\tests\\unit\\data\n",
      "      copying tests\\unit\\data\\metadataset_test.py -> build\\lib.win-amd64-cpython-311\\tests\\unit\\data\n",
      "      copying tests\\unit\\data\\task_dataset_test.py -> build\\lib.win-amd64-cpython-311\\tests\\unit\\data\n",
      "      copying tests\\unit\\data\\transforms_test.py -> build\\lib.win-amd64-cpython-311\\tests\\unit\\data\n",
      "      copying tests\\unit\\data\\utils_test.py -> build\\lib.win-amd64-cpython-311\\tests\\unit\\data\n",
      "      copying tests\\unit\\data\\util_datasets.py -> build\\lib.win-amd64-cpython-311\\tests\\unit\\data\n",
      "      copying tests\\unit\\data\\__init__.py -> build\\lib.win-amd64-cpython-311\\tests\\unit\\data\n",
      "      creating build\\lib.win-amd64-cpython-311\\tests\\unit\\nn\n",
      "      copying tests\\unit\\nn\\kroneckers_test.py -> build\\lib.win-amd64-cpython-311\\tests\\unit\\nn\n",
      "      copying tests\\unit\\nn\\metaoptnet_test_notravis.py -> build\\lib.win-amd64-cpython-311\\tests\\unit\\nn\n",
      "      copying tests\\unit\\nn\\misc.py -> build\\lib.win-amd64-cpython-311\\tests\\unit\\nn\n",
      "      copying tests\\unit\\nn\\protonet_test.py -> build\\lib.win-amd64-cpython-311\\tests\\unit\\nn\n",
      "      copying tests\\unit\\nn\\__init__.py -> build\\lib.win-amd64-cpython-311\\tests\\unit\\nn\n",
      "      creating build\\lib.win-amd64-cpython-311\\tests\\unit\\vision\n",
      "      copying tests\\unit\\vision\\benchmarks_test_notravis.py -> build\\lib.win-amd64-cpython-311\\tests\\unit\\vision\n",
      "      copying tests\\unit\\vision\\cifarfs_test_notravis.py -> build\\lib.win-amd64-cpython-311\\tests\\unit\\vision\n",
      "      copying tests\\unit\\vision\\cu_birds200_test_notravis.py -> build\\lib.win-amd64-cpython-311\\tests\\unit\\vision\n",
      "      copying tests\\unit\\vision\\describable_textures_test_notravis.py -> build\\lib.win-amd64-cpython-311\\tests\\unit\\vision\n",
      "      copying tests\\unit\\vision\\fc100_test_notravis.py -> build\\lib.win-amd64-cpython-311\\tests\\unit\\vision\n",
      "      copying tests\\unit\\vision\\fgvc_aircraft_test_notravis.py -> build\\lib.win-amd64-cpython-311\\tests\\unit\\vision\n",
      "      copying tests\\unit\\vision\\pretrained_backbones_notravis.py -> build\\lib.win-amd64-cpython-311\\tests\\unit\\vision\n",
      "      copying tests\\unit\\vision\\quickdraw_test_no.py -> build\\lib.win-amd64-cpython-311\\tests\\unit\\vision\n",
      "      copying tests\\unit\\vision\\tiered_imagenet_test_notravis.py -> build\\lib.win-amd64-cpython-311\\tests\\unit\\vision\n",
      "      copying tests\\unit\\vision\\transform_test_notravis.py -> build\\lib.win-amd64-cpython-311\\tests\\unit\\vision\n",
      "      copying tests\\unit\\vision\\vgg_flowers_test_notravis.py -> build\\lib.win-amd64-cpython-311\\tests\\unit\\vision\n",
      "      copying tests\\unit\\vision\\__init__.py -> build\\lib.win-amd64-cpython-311\\tests\\unit\\vision\n",
      "      running build_ext\n",
      "      building 'learn2learn.data.meta_dataset' extension\n",
      "      creating build\\temp.win-amd64-cpython-311\\Release\\learn2learn\\data\n",
      "      \"C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.38.33130\\bin\\HostX86\\x64\\cl.exe\" /c /nologo /O2 /W3 /GL /DNDEBUG /MD -IC:\\Users\\zelbo\\anaconda3\\envs\\dassl\\include -IC:\\Users\\zelbo\\anaconda3\\envs\\dassl\\Include \"-IC:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.38.33130\\include\" \"-IC:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.38.33130\\ATLMFC\\include\" \"-IC:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Auxiliary\\VS\\include\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.22621.0\\ucrt\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.22621.0\\\\um\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.22621.0\\\\shared\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.22621.0\\\\winrt\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.22621.0\\\\cppwinrt\" \"-IC:\\Program Files (x86)\\Windows Kits\\NETFXSDK\\4.8\\include\\um\" /Tclearn2learn/data/meta_dataset.c /Fobuild\\temp.win-amd64-cpython-311\\Release\\learn2learn/data/meta_dataset.obj\n",
      "      meta_dataset.c\n",
      "      learn2learn/data/meta_dataset.c(210): fatal error C1083: Cannot open include file: 'longintrepr.h': No such file or directory\n",
      "      error: command 'C:\\\\Program Files\\\\Microsoft Visual Studio\\\\2022\\\\Community\\\\VC\\\\Tools\\\\MSVC\\\\14.38.33130\\\\bin\\\\HostX86\\\\x64\\\\cl.exe' failed with exit code 2\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for learn2learn\n",
      "ERROR: Could not build wheels for learn2learn, which is required to install pyproject.toml-based projects\n",
      "\n",
      "[notice] A new release of pip is available: 23.3.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "A subdirectory or file outputs already exists.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zelbo\\Documents\\__SHARING FOLDER\\University\\Year K\\Deep Learning\\Homework\\KUDeepLearning\\DL_HW4\\ProMetaR\\data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A subdirectory or file data already exists.\n",
      "A subdirectory or file eurosat already exists.\n",
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zelbo\\Documents\\__SHARING FOLDER\\University\\Year K\\Deep Learning\\Homework\\KUDeepLearning\\DL_HW4\\ProMetaR\\data\\eurosat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "unzip:  cannot find either EuroSAT.zip or EuroSAT.zip.zip.\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1Ip7yaCWFi0eaOFUGga0lUdVi_DDQth1o\n",
      "To: c:\\Users\\zelbo\\Documents\\__SHARING FOLDER\\University\\Year K\\Deep Learning\\Homework\\KUDeepLearning\\DL_HW4\\ProMetaR\\data\\eurosat\\split_zhou_EuroSAT.json\n",
      "\n",
      "  0%|          | 0.00/3.01M [00:00<?, ?B/s]\n",
      " 17%|█▋        | 524k/3.01M [00:00<00:00, 2.83MB/s]\n",
      " 52%|█████▏    | 1.57M/3.01M [00:00<00:00, 6.08MB/s]\n",
      "100%|██████████| 3.01M/3.01M [00:00<00:00, 8.69MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zelbo\\Documents\\__SHARING FOLDER\\University\\Year K\\Deep Learning\\Homework\\KUDeepLearning\\DL_HW4\\ProMetaR\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'dassl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [1], line 45\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdatetime\u001b[39;00m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01margparse\u001b[39;00m\n\u001b[1;32m---> 45\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdassl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m setup_logger, set_random_seed, collect_env_info\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdassl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_cfg_default\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdassl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m build_trainer\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'dassl'"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/mlvlab/ProMetaR.git\n",
    "%cd ProMetaR/\n",
    "\n",
    "!git clone https://github.com/KaiyangZhou/Dassl.pytorch.git\n",
    "%cd Dassl.pytorch/\n",
    "\n",
    "# Install dependencies\n",
    "!pip install -r requirements.txt\n",
    "!copy -r dassl ../\n",
    "# Install this library (no need to re-build if the source code is modified)\n",
    "# !python setup.py develop\n",
    "%cd ..\n",
    "\n",
    "!pip install -r requirements.txt\n",
    "\n",
    "%mkdir outputs\n",
    "%mkdir data\n",
    "\n",
    "%cd data\n",
    "%mkdir eurosat\n",
    "!wget http://madm.dfki.de/files/sentinel/EuroSAT.zip EuroSAT.zip\n",
    "\n",
    "!unzip -o EuroSAT.zip -d eurosat/\n",
    "%cd eurosat\n",
    "!gdown 1Ip7yaCWFi0eaOFUGga0lUdVi_DDQth1o\n",
    "\n",
    "%cd ../../\n",
    "\n",
    "import os.path as osp\n",
    "from collections import OrderedDict\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "from clip import clip\n",
    "from clip.simple_tokenizer import SimpleTokenizer as _Tokenizer\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import datetime\n",
    "import argparse\n",
    "from dassl.utils import setup_logger, set_random_seed, collect_env_info\n",
    "from dassl.config import get_cfg_default\n",
    "from dassl.engine import build_trainer\n",
    "from dassl.engine import TRAINER_REGISTRY, TrainerX\n",
    "from dassl.metrics import compute_accuracy\n",
    "from dassl.utils import load_pretrained_weights, load_checkpoint\n",
    "from dassl.optim import build_optimizer, build_lr_scheduler\n",
    "\n",
    "# custom\n",
    "import datasets.oxford_pets\n",
    "import datasets.oxford_flowers\n",
    "import datasets.fgvc_aircraft\n",
    "import datasets.dtd\n",
    "import datasets.eurosat\n",
    "import datasets.stanford_cars\n",
    "import datasets.food101\n",
    "import datasets.sun397\n",
    "import datasets.caltech101\n",
    "import datasets.ucf101\n",
    "import datasets.imagenet\n",
    "import datasets.imagenet_sketch\n",
    "import datasets.imagenetv2\n",
    "import datasets.imagenet_a\n",
    "import datasets.imagenet_r\n",
    "\n",
    "def print_args(args, cfg):\n",
    "    print(\"***************\")\n",
    "    print(\"** Arguments **\")\n",
    "    print(\"***************\")\n",
    "    optkeys = list(args.__dict__.keys())\n",
    "    optkeys.sort()\n",
    "    for key in optkeys:\n",
    "        print(\"{}: {}\".format(key, args.__dict__[key]))\n",
    "    print(\"************\")\n",
    "    print(\"** Config **\")\n",
    "    print(\"************\")\n",
    "    print(cfg)\n",
    "\n",
    "def reset_cfg(cfg, args):\n",
    "    if args.root:\n",
    "        cfg.DATASET.ROOT = args.root\n",
    "    if args.output_dir:\n",
    "        cfg.OUTPUT_DIR = args.output_dir\n",
    "    if args.seed:\n",
    "        cfg.SEED = args.seed\n",
    "    if args.trainer:\n",
    "        cfg.TRAINER.NAME = args.trainer\n",
    "    cfg.DATASET.NUM_SHOTS = 16\n",
    "    cfg.DATASET.SUBSAMPLE_CLASSES = args.subsample_classes\n",
    "    cfg.DATALOADER.TRAIN_X.BATCH_SIZE = args.train_batch_size\n",
    "    cfg.OPTIM.MAX_EPOCH = args.epoch\n",
    "\n",
    "def extend_cfg(cfg):\n",
    "    \"\"\"\n",
    "    Add new config variables.\n",
    "    \"\"\"\n",
    "    from yacs.config import CfgNode as CN\n",
    "    cfg.TRAINER.COOP = CN()\n",
    "    cfg.TRAINER.COOP.N_CTX = 16  # number of context vectors\n",
    "    cfg.TRAINER.COOP.CSC = False  # class-specific context\n",
    "    cfg.TRAINER.COOP.CTX_INIT = \"\"  # initialization words\n",
    "    cfg.TRAINER.COOP.PREC = \"fp16\"  # fp16, fp32, amp\n",
    "    cfg.TRAINER.COOP.CLASS_TOKEN_POSITION = \"end\"  # 'middle' or 'end' or 'front'\n",
    "    cfg.TRAINER.COCOOP = CN()\n",
    "    cfg.TRAINER.COCOOP.N_CTX = 4  # number of context vectors\n",
    "    cfg.TRAINER.COCOOP.CTX_INIT = \"a photo of a\"  # initialization words\n",
    "    cfg.TRAINER.COCOOP.PREC = \"fp16\"  # fp16, fp32, amp\n",
    "    cfg.TRAINER.PROMETAR = CN()\n",
    "    cfg.TRAINER.PROMETAR.N_CTX_VISION = 4  # number of context vectors at the vision branch\n",
    "    cfg.TRAINER.PROMETAR.N_CTX_TEXT = 4  # number of context vectors at the language branch\n",
    "    cfg.TRAINER.PROMETAR.CTX_INIT = \"a photo of a\"  # initialization words\n",
    "    cfg.TRAINER.PROMETAR.PREC = \"fp16\"  # fp16, fp32, amp\n",
    "    cfg.TRAINER.PROMETAR.PROMPT_DEPTH_VISION = 9  # Max 12, minimum 0, for 0 it will be using shallow IVLP prompting (J=1)\n",
    "    cfg.TRAINER.PROMETAR.PROMPT_DEPTH_TEXT = 9  # Max 12, minimum 0, for 0 it will be using shallow IVLP prompting (J=1)\n",
    "    cfg.DATASET.SUBSAMPLE_CLASSES = \"all\"  # all, base or new\n",
    "    cfg.TRAINER.PROMETAR.ADAPT_LR = 0.0005\n",
    "    cfg.TRAINER.PROMETAR.LR_RATIO = 0.0005\n",
    "    cfg.TRAINER.PROMETAR.FAST_ADAPTATION = False\n",
    "    cfg.TRAINER.PROMETAR.MIXUP_ALPHA = 0.5\n",
    "    cfg.TRAINER.PROMETAR.MIXUP_BETA = 0.5\n",
    "    cfg.TRAINER.PROMETAR.DIM_RATE=8\n",
    "    cfg.OPTIM_VNET = CN()\n",
    "    cfg.OPTIM_VNET.NAME = \"adam\"\n",
    "    cfg.OPTIM_VNET.LR = 0.0003\n",
    "    cfg.OPTIM_VNET.WEIGHT_DECAY = 5e-4\n",
    "    cfg.OPTIM_VNET.MOMENTUM = 0.9\n",
    "    cfg.OPTIM_VNET.SGD_DAMPNING = 0\n",
    "    cfg.OPTIM_VNET.SGD_NESTEROV = False\n",
    "    cfg.OPTIM_VNET.RMSPROP_ALPHA = 0.99\n",
    "    cfg.OPTIM_VNET.ADAM_BETA1 = 0.9\n",
    "    cfg.OPTIM_VNET.ADAM_BETA2 = 0.999\n",
    "    cfg.OPTIM_VNET.STAGED_LR = False\n",
    "    cfg.OPTIM_VNET.NEW_LAYERS = ()\n",
    "    cfg.OPTIM_VNET.BASE_LR_MULT = 0.1\n",
    "    # Learning rate scheduler\n",
    "    cfg.OPTIM_VNET.LR_SCHEDULER = \"single_step\"\n",
    "    # -1 or 0 means the stepsize is equal to max_epoch\n",
    "    cfg.OPTIM_VNET.STEPSIZE = (-1, )\n",
    "    cfg.OPTIM_VNET.GAMMA = 0.1\n",
    "    cfg.OPTIM_VNET.MAX_EPOCH = 10\n",
    "    # Set WARMUP_EPOCH larger than 0 to activate warmup training\n",
    "    cfg.OPTIM_VNET.WARMUP_EPOCH = -1\n",
    "    # Either linear or constant\n",
    "    cfg.OPTIM_VNET.WARMUP_TYPE = \"linear\"\n",
    "    # Constant learning rate when type=constant\n",
    "    cfg.OPTIM_VNET.WARMUP_CONS_LR = 1e-5\n",
    "    # Minimum learning rate when type=linear\n",
    "    cfg.OPTIM_VNET.WARMUP_MIN_LR = 1e-5\n",
    "    # Recount epoch for the next scheduler (last_epoch=-1)\n",
    "    # Otherwise last_epoch=warmup_epoch\n",
    "    cfg.OPTIM_VNET.WARMUP_RECOUNT = True\n",
    "\n",
    "def setup_cfg(args):\n",
    "    cfg = get_cfg_default()\n",
    "    extend_cfg(cfg)\n",
    "    # 1. From the dataset config file\n",
    "    if args.dataset_config_file:\n",
    "        cfg.merge_from_file(args.dataset_config_file)\n",
    "    # 2. From the method config file\n",
    "    if args.config_file:\n",
    "        cfg.merge_from_file(args.config_file)\n",
    "    # 3. From input arguments\n",
    "    reset_cfg(cfg, args)\n",
    "    cfg.freeze()\n",
    "    return cfg\n",
    "\n",
    "_tokenizer = _Tokenizer()\n",
    "\n",
    "def load_clip_to_cpu(cfg): # Load CLIP\n",
    "    backbone_name = cfg.MODEL.BACKBONE.NAME\n",
    "    url = clip._MODELS[backbone_name]\n",
    "    model_path = clip._download(url)\n",
    "\n",
    "    try:\n",
    "        # loading JIT archive\n",
    "        model = torch.jit.load(model_path, map_location=\"cpu\").eval()\n",
    "        state_dict = None\n",
    "\n",
    "    except RuntimeError:\n",
    "        state_dict = torch.load(model_path, map_location=\"cpu\")\n",
    "\n",
    "    if cfg.TRAINER.NAME == \"\":\n",
    "      design_trainer = \"CoOp\"\n",
    "    else:\n",
    "      design_trainer = cfg.TRAINER.NAME\n",
    "    design_details = {\"trainer\": design_trainer,\n",
    "                      \"vision_depth\": 0,\n",
    "                      \"language_depth\": 0, \"vision_ctx\": 0,\n",
    "                      \"language_ctx\": 0}\n",
    "    model = clip.build_model(state_dict or model.state_dict(), design_details)\n",
    "\n",
    "    return model\n",
    "\n",
    "from dassl.config import get_cfg_default\n",
    "cfg = get_cfg_default()\n",
    "cfg.MODEL.BACKBONE.NAME = \"ViT-B/16\" # Set the vision encoder backbone of CLIP to ViT.\n",
    "clip_model = load_clip_to_cpu(cfg)\n",
    "\n",
    "\n",
    "\n",
    "class TextEncoder(nn.Module):\n",
    "    def __init__(self, clip_model): # 초기화 하는 함수\n",
    "        super().__init__()\n",
    "        self.transformer = clip_model.transformer\n",
    "        self.positional_embedding = clip_model.positional_embedding\n",
    "        self.ln_final = clip_model.ln_final\n",
    "        self.text_projection = clip_model.text_projection\n",
    "        self.dtype = clip_model.dtype\n",
    "\n",
    "    def forward(self, prompts, tokenized_prompts): # 모델 호출\n",
    "        x = prompts + self.positional_embedding.type(self.dtype)\n",
    "        x = x.permute(1, 0, 2)  # NLD -> LND\n",
    "        x = self.transformer(x)\n",
    "        x = x.permute(1, 0, 2)  # LND -> NLD\n",
    "        x = self.ln_final(x).type(self.dtype)\n",
    "\n",
    "        # x.shape = [batch_size, n_ctx, transformer.width]\n",
    "        # take features from the eot embedding (eot_token is the highest number in each sequence)\n",
    "        x = x[torch.arange(x.shape[0]), tokenized_prompts.argmax(dim=-1)] @ self.text_projection\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "@TRAINER_REGISTRY.register(force=True)\n",
    "class CoCoOp(TrainerX):\n",
    "    def check_cfg(self, cfg):\n",
    "        assert cfg.TRAINER.COCOOP.PREC in [\"fp16\", \"fp32\", \"amp\"]\n",
    "\n",
    "    def build_model(self):\n",
    "        cfg = self.cfg\n",
    "        classnames = self.dm.dataset.classnames\n",
    "        print(f\"Loading CLIP (backbone: {cfg.MODEL.BACKBONE.NAME})\")\n",
    "        clip_model = load_clip_to_cpu(cfg)\n",
    "\n",
    "        if cfg.TRAINER.COCOOP.PREC == \"fp32\" or cfg.TRAINER.COCOOP.PREC == \"amp\":\n",
    "            # CLIP's default precision is fp16\n",
    "            clip_model.float()\n",
    "\n",
    "        print(\"Building custom CLIP\")\n",
    "        self.model = CoCoOpCustomCLIP(cfg, classnames, clip_model)\n",
    "\n",
    "        print(\"Turning off gradients in both the image and the text encoder\")\n",
    "        name_to_update = \"prompt_learner\"\n",
    "\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if name_to_update not in name:\n",
    "                param.requires_grad_(False)\n",
    "\n",
    "        # Double check\n",
    "        enabled = set()\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                enabled.add(name)\n",
    "        print(f\"Parameters to be updated: {enabled}\")\n",
    "\n",
    "        if cfg.MODEL.INIT_WEIGHTS:\n",
    "            load_pretrained_weights(self.model.prompt_learner, cfg.MODEL.INIT_WEIGHTS)\n",
    "\n",
    "        self.model.to(self.device)\n",
    "        # NOTE: only give prompt_learner to the optimizer\n",
    "        self.optim = build_optimizer(self.model.prompt_learner, cfg.OPTIM)\n",
    "        self.sched = build_lr_scheduler(self.optim, cfg.OPTIM)\n",
    "        self.register_model(\"prompt_learner\", self.model.prompt_learner, self.optim, self.sched)\n",
    "\n",
    "        self.scaler = GradScaler() if cfg.TRAINER.COCOOP.PREC == \"amp\" else None\n",
    "\n",
    "        # Note that multi-gpu training could be slow because CLIP's size is\n",
    "        # big, which slows down the copy operation in DataParallel\n",
    "        device_count = torch.cuda.device_count()\n",
    "        if device_count > 1:\n",
    "            print(f\"Multiple GPUs detected (n_gpus={device_count}), use all of them!\")\n",
    "            self.model = nn.DataParallel(self.model)\n",
    "\n",
    "    def before_train(self):\n",
    "        directory = self.cfg.OUTPUT_DIR\n",
    "        if self.cfg.RESUME:\n",
    "            directory = self.cfg.RESUME\n",
    "        self.start_epoch = self.resume_model_if_exist(directory)\n",
    "\n",
    "        # Remember the starting time (for computing the elapsed time)\n",
    "        self.time_start = time.time()\n",
    "\n",
    "\n",
    "    def forward_backward(self, batch):\n",
    "        image, label = self.parse_batch_train(batch)\n",
    "\n",
    "        model = self.model\n",
    "        optim = self.optim\n",
    "        scaler = self.scaler\n",
    "\n",
    "        prec = self.cfg.TRAINER.COCOOP.PREC\n",
    "        loss = model(image, label) # Input image 모델 통과\n",
    "        optim.zero_grad()\n",
    "        loss.backward() # Backward (역전파)\n",
    "        optim.step() # 모델 parameter update\n",
    "\n",
    "        loss_summary = {\"loss\": loss.item()}\n",
    "\n",
    "        if (self.batch_idx + 1) == self.num_batches:\n",
    "            self.update_lr()\n",
    "\n",
    "        return loss_summary\n",
    "\n",
    "    def parse_batch_train(self, batch):\n",
    "        input = batch[\"img\"]\n",
    "        label = batch[\"label\"]\n",
    "        input = input.to(self.device)\n",
    "        label = label.to(self.device)\n",
    "        return input, label\n",
    "\n",
    "    def load_model(self, directory, epoch=None):\n",
    "        if not directory:\n",
    "            print(\"Note that load_model() is skipped as no pretrained model is given\")\n",
    "            return\n",
    "\n",
    "        names = self.get_model_names()\n",
    "\n",
    "        # By default, the best model is loaded\n",
    "        model_file = \"model-best.pth.tar\"\n",
    "\n",
    "        if epoch is not None:\n",
    "            model_file = \"model.pth.tar-\" + str(epoch)\n",
    "\n",
    "        for name in names:\n",
    "            model_path = osp.join(directory, name, model_file)\n",
    "\n",
    "            if not osp.exists(model_path):\n",
    "                raise FileNotFoundError('Model not found at \"{}\"'.format(model_path))\n",
    "\n",
    "            checkpoint = load_checkpoint(model_path)\n",
    "            state_dict = checkpoint[\"state_dict\"]\n",
    "            epoch = checkpoint[\"epoch\"]\n",
    "\n",
    "            # Ignore fixed token vectors\n",
    "            if \"token_prefix\" in state_dict:\n",
    "                del state_dict[\"token_prefix\"]\n",
    "\n",
    "            if \"token_suffix\" in state_dict:\n",
    "                del state_dict[\"token_suffix\"]\n",
    "\n",
    "            print(\"Loading weights to {} \" 'from \"{}\" (epoch = {})'.format(name, model_path, epoch))\n",
    "            # set strict=False\n",
    "            self._models[name].load_state_dict(state_dict, strict=False)\n",
    "\n",
    "    def after_train(self):\n",
    "      print(\"Finish training\")\n",
    "\n",
    "      do_test = not self.cfg.TEST.NO_TEST\n",
    "      if do_test:\n",
    "          if self.cfg.TEST.FINAL_MODEL == \"best_val\":\n",
    "              print(\"Deploy the model with the best val performance\")\n",
    "              self.load_model(self.output_dir)\n",
    "          else:\n",
    "              print(\"Deploy the last-epoch model\")\n",
    "          acc = self.test()\n",
    "\n",
    "      # Show elapsed time\n",
    "      elapsed = round(time.time() - self.time_start)\n",
    "      elapsed = str(datetime.timedelta(seconds=elapsed))\n",
    "      print(f\"Elapsed: {elapsed}\")\n",
    "\n",
    "      # Close writer\n",
    "      self.close_writer()\n",
    "      return acc\n",
    "\n",
    "    def train(self):\n",
    "        \"\"\"Generic training loops.\"\"\"\n",
    "        self.before_train()\n",
    "        for self.epoch in range(self.start_epoch, self.max_epoch):\n",
    "            self.before_epoch()\n",
    "            self.run_epoch()\n",
    "            self.after_epoch()\n",
    "        acc = self.after_train()\n",
    "        return acc\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--root\", type=str, default=\"data/\", help=\"path to dataset\")\n",
    "parser.add_argument(\"--output-dir\", type=str, default=\"outputs/cocoop3\", help=\"output directory\")\n",
    "parser.add_argument(\n",
    "    \"--seed\", type=int, default=1, help=\"only positive value enables a fixed seed\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--config-file\", type=str, default=\"configs/trainers/ProMetaR/vit_b16_c2_ep10_batch4_4+4ctx.yaml\", help=\"path to config file\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--dataset-config-file\",\n",
    "    type=str,\n",
    "    default=\"configs/datasets/eurosat.yaml\",\n",
    "    help=\"path to config file for dataset setup\",\n",
    ")\n",
    "parser.add_argument(\"--trainer\", type=str, default=\"CoOp\", help=\"name of trainer\")\n",
    "parser.add_argument(\"--eval-only\", action=\"store_true\", help=\"evaluation only\")\n",
    "parser.add_argument(\n",
    "    \"--model-dir\",\n",
    "    type=str,\n",
    "    default=\"\",\n",
    "    help=\"load model from this directory for eval-only mode\",\n",
    ")\n",
    "parser.add_argument(\"--train-batch-size\", type=int, default=4)\n",
    "parser.add_argument(\"--epoch\", type=int, default=10)\n",
    "parser.add_argument(\"--subsample-classes\", type=str, default=\"base\")\n",
    "parser.add_argument(\n",
    "    \"--load-epoch\", type=int, default=0, help=\"load model weights at this epoch for evaluation\"\n",
    ")\n",
    "args = parser.parse_args([])\n",
    "\n",
    "def main(args):\n",
    "    cfg = setup_cfg(args)\n",
    "    if cfg.SEED >= 0:\n",
    "        set_random_seed(cfg.SEED)\n",
    "\n",
    "    if torch.cuda.is_available() and cfg.USE_CUDA:\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "\n",
    "    trainer = build_trainer(cfg)\n",
    "    if args.eval_only:\n",
    "        trainer.load_model(args.model_dir, epoch=args.load_epoch)\n",
    "        acc = trainer.test()\n",
    "        return acc\n",
    "\n",
    "    acc = trainer.train()\n",
    "    return acc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "G3n9blo4JO7m"
   },
   "source": [
    "### **Q1.  Understanding and implementing CoCoOp**\n",
    "* We have learned how to define CoOp in Lab Session 4.\n",
    "\n",
    "* The main difference between CoOp and CoCoOp is **meta network** to extract image tokens that is added to the text prompt.\n",
    "\n",
    "* Based on the CoOp code given in Lab Session 4, fill-in-the-blank exercise to test your understanding of critical parts of the CoCoOp.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SONlVIhPH_qF"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class CoCoOpPromptLearner(nn.Module):\n",
    "    def __init__(self, cfg, classnames, clip_model):\n",
    "        super().__init__()\n",
    "        n_cls = len(classnames)\n",
    "        n_ctx = cfg.TRAINER.COCOOP.N_CTX\n",
    "        ctx_init = cfg.TRAINER.COCOOP.CTX_INIT\n",
    "        dtype = clip_model.dtype\n",
    "        ctx_dim = clip_model.ln_final.weight.shape[0]\n",
    "        vis_dim = clip_model.visual.output_dim\n",
    "        clip_imsize = clip_model.visual.input_resolution\n",
    "        cfg_imsize = cfg.INPUT.SIZE[0]\n",
    "        assert cfg_imsize == clip_imsize, f\"cfg_imsize ({cfg_imsize}) must equal to clip_imsize ({clip_imsize})\"\n",
    "\n",
    "        if ctx_init:\n",
    "            # use given words to initialize context vectors\n",
    "            ctx_init = ctx_init.replace(\"_\", \" \")\n",
    "            n_ctx = len(ctx_init.split(\" \"))\n",
    "            prompt = clip.tokenize(ctx_init)\n",
    "            with torch.no_grad():\n",
    "                embedding = clip_model.token_embedding(prompt).type(dtype)\n",
    "            ctx_vectors = embedding[0, 1: 1 + n_ctx, :]\n",
    "            prompt_prefix = ctx_init\n",
    "        else:\n",
    "            # random initialization\n",
    "            ctx_vectors = torch.empty(n_ctx, ctx_dim, dtype=dtype)\n",
    "            nn.init.normal_(ctx_vectors, std=0.02)\n",
    "            prompt_prefix = \" \".join([\"X\"] * n_ctx)\n",
    "\n",
    "        print(f'Initial context: \"{prompt_prefix}\"')\n",
    "        print(f\"Number of context words (tokens): {n_ctx}\")\n",
    "\n",
    "        self.ctx = nn.Parameter(ctx_vectors)  # Wrap the initialized prompts above as parameters to make them trainable.\n",
    "\n",
    "        ### Tokenize ###\n",
    "        classnames = [name.replace(\"_\", \" \") for name in classnames]  # 예) \"Forest\"\n",
    "        name_lens = [len(_tokenizer.encode(name)) for name in classnames]\n",
    "        prompts = [prompt_prefix + \" \" + name + \".\" for name in classnames] # 예) \"A photo of Forest.\"\n",
    "\n",
    "        tokenized_prompts = torch.cat([clip.tokenize(p) for p in prompts]) # 예) [49406, 320, 1125, 539...]\n",
    "\n",
    "\n",
    "\n",
    "        #####################################\n",
    "        ####### Q1. Fill in the blank #######\n",
    "        ########## Define Meta Net ##########\n",
    "        self.meta_net = nn.Sequential(OrderedDict([\n",
    "            #(\"linear1\", \"fill in here\"(vis_dim, vis_dim // 16)),\n",
    "            (\"linear1\", nn.Linear(vis_dim, vis_dim // 16)),\n",
    "            (\"relu\", nn.ReLU(inplace=True)),\n",
    "            (\"linear2\", nn.Linear(vis_dim // 16, ctx_dim))\n",
    "        ]))\n",
    "        #####################################\n",
    "        ## Hint: meta network is composed to linear layer, relu activation, and linear layer.\n",
    "\n",
    "\n",
    "\n",
    "        if cfg.TRAINER.COCOOP.PREC == \"fp16\":\n",
    "            self.meta_net.half()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            embedding = clip_model.token_embedding(tokenized_prompts).type(dtype)\n",
    "\n",
    "        # These token vectors will be saved when in save_model(),\n",
    "        # but they should be ignored in load_model() as we want to use\n",
    "        # those computed using the current class names\n",
    "        self.register_buffer(\"token_prefix\", embedding[:, :1, :])  # SOS\n",
    "        self.register_buffer(\"token_suffix\", embedding[:, 1 + n_ctx:, :])  # CLS, EOS\n",
    "        self.n_cls = n_cls\n",
    "        self.n_ctx = n_ctx\n",
    "        self.tokenized_prompts = tokenized_prompts  # torch.Tensor\n",
    "        self.name_lens = name_lens\n",
    "\n",
    "    def construct_prompts(self, ctx, prefix, suffix, label=None):\n",
    "        # dim0 is either batch_size (during training) or n_cls (during testing)\n",
    "        # ctx: context tokens, with shape of (dim0, n_ctx, ctx_dim)\n",
    "        # prefix: the sos token, with shape of (n_cls, 1, ctx_dim)\n",
    "        # suffix: remaining tokens, with shape of (n_cls, *, ctx_dim)\n",
    "\n",
    "        if label is not None:\n",
    "            prefix = prefix[label]\n",
    "            suffix = suffix[label]\n",
    "\n",
    "        prompts = torch.cat(\n",
    "            [\n",
    "                prefix,  # (dim0, 1, dim)\n",
    "                ctx,  # (dim0, n_ctx, dim)\n",
    "                suffix,  # (dim0, *, dim)\n",
    "            ],\n",
    "            dim=1,\n",
    "        )\n",
    "\n",
    "        return prompts\n",
    "\n",
    "    def forward(self, im_features):\n",
    "        prefix = self.token_prefix\n",
    "        suffix = self.token_suffix\n",
    "        ctx = self.ctx  # (n_ctx, ctx_dim)\n",
    "\n",
    "\n",
    "\n",
    "        ############################################\n",
    "        ########## Q2,3. Fill in the blank #########\n",
    "        #bias = self.meta_net(\"Fill in here, Hint: Image feature is given as input to meta network\")  # (batch, ctx_dim)\n",
    "        bias = self.meta_net(im_features)  # (batch, ctx_dim)\n",
    "        bias = bias.unsqueeze(1)  # (batch, 1, ctx_dim)\n",
    "        ctx = ctx.unsqueeze(0)  # (1, n_ctx, ctx_dim)\n",
    "        #ctx_shifted = ctx + \"Fill in here, Hint: Add meta token to context token\"  # (batch, n_ctx, ctx_dim)\n",
    "        ctx_shifted = ctx + bias  # (batch, n_ctx, ctx_dim)\n",
    "        ############################################\n",
    "        ############################################\n",
    "\n",
    "\n",
    "\n",
    "        # Use instance-conditioned context tokens for all classes\n",
    "        prompts = []\n",
    "        for ctx_shifted_i in ctx_shifted:\n",
    "            ctx_i = ctx_shifted_i.unsqueeze(0).expand(self.n_cls, -1, -1)\n",
    "            pts_i = self.construct_prompts(ctx_i, prefix, suffix)  # (n_cls, n_tkn, ctx_dim)\n",
    "            prompts.append(pts_i)\n",
    "        prompts = torch.stack(prompts)\n",
    "\n",
    "        return prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L_BluKEdKA94"
   },
   "outputs": [],
   "source": [
    "class CoCoOpCustomCLIP(nn.Module):\n",
    "    def __init__(self, cfg, classnames, clip_model):\n",
    "        super().__init__()\n",
    "        self.prompt_learner = CoCoOpPromptLearner(cfg, classnames, clip_model)\n",
    "        self.tokenized_prompts = self.prompt_learner.tokenized_prompts\n",
    "        self.image_encoder = clip_model.visual\n",
    "        self.text_encoder = TextEncoder(clip_model)\n",
    "        self.logit_scale = clip_model.logit_scale\n",
    "        self.dtype = clip_model.dtype\n",
    "\n",
    "    def forward(self, image, label=None):\n",
    "        tokenized_prompts = self.tokenized_prompts\n",
    "        logit_scale = self.logit_scale.exp()\n",
    "\n",
    "        image_features = self.image_encoder(image.type(self.dtype))\n",
    "        image_features = image_features / image_features.norm(dim=-1, keepdim=True)\n",
    "\n",
    "\n",
    "        ############################################\n",
    "        ########## Q4. Fill in the blank #########\n",
    "        #prompts = self.prompt_learner(\"Fill in here\")\n",
    "        prompts = self.prompt_learner(image_features)\n",
    "        ############################################\n",
    "        ############################################\n",
    "\n",
    "\n",
    "        logits = []\n",
    "        for pts_i, imf_i in zip(prompts, image_features):\n",
    "            text_features = self.text_encoder(pts_i, tokenized_prompts)\n",
    "            text_features = text_features / text_features.norm(dim=-1, keepdim=True)\n",
    "            l_i = logit_scale * imf_i @ text_features.t()\n",
    "            logits.append(l_i)\n",
    "        logits = torch.stack(logits)\n",
    "\n",
    "        if self.prompt_learner.training:\n",
    "            return F.cross_entropy(logits, label)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "2CGZlqo-HtRN"
   },
   "source": [
    "### **Q2. Trainining CoCoOp**\n",
    "\n",
    "In this task, you will train CoCoOp on the EuroSAT dataset. If your implementation of CoCoOp in Question 1 is correct, the following code should execute without errors. Please submit the execution file so we can evaluate whether your code runs without any issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zy3bAMnBMrXP"
   },
   "outputs": [],
   "source": [
    "# Train on the Base Classes Train split and evaluate accuracy on the Base Classes Test split.\n",
    "args.trainer = \"CoCoOp\"\n",
    "args.train_batch_size = 4\n",
    "args.epoch = 100\n",
    "args.output_dir = \"outputs/cocoop\"\n",
    "\n",
    "args.subsample_classes = \"base\"\n",
    "args.eval_only = False\n",
    "cocoop_base_acc = main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xql7WpJ5vPII"
   },
   "outputs": [],
   "source": [
    "# Accuracy on the New Classes.\n",
    "args.model_dir = \"outputs/cocoop\"\n",
    "args.output_dir = \"outputs/cocoop/new_classes\"\n",
    "args.subsample_classes = \"new\"\n",
    "args.load_epoch = 100\n",
    "args.eval_only = True\n",
    "coop_novel_acc = main(args)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "l1KdgiKFsowj"
   },
   "source": [
    "### **Q3. Analyzing the results of CoCoOp**\n",
    "Compare the results of CoCoOp with those of CoOp that we trained in Lab Session 4. Discuss possible reasons for the performance differences observed between CoCoOp and CoOp."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "G3n9blo4JO7m",
    "2CGZlqo-HtRN"
   ],
   "gpuType": "T4",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "dassl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
